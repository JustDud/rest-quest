Drop any mock answer videos here (e.g., `q1.mp4`, `q2.mp4`).  
`project/camera.py` will consume them in alphabetical order before falling back to the webcam feed.  
Each clip should roughly match the listening window (default 10 seconds) so the emotion spectrum reflects the full response. 
